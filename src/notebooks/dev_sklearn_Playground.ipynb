{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>language_labels</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23081</td>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @ RD _ BANA Kahan Ho ???? Zinda Samadhi Kab...</td>\n",
       "      <td>['Eng', 'O', 'Hin', 'O', 'Hin', 'Hin', 'Hin', ...</td>\n",
       "      <td>rt mention rd bana kahan ho zinda samadhi kab ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29854</td>\n",
       "      <td>negative</td>\n",
       "      <td>In pro-indian hazraat ka Bughazzay Pak fauj da...</td>\n",
       "      <td>['Eng', 'Eng', 'Hin', 'Hin', 'Eng', 'Hin', 'En...</td>\n",
       "      <td>in proindian hazraat ka bughazzay pak fauj dai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35319</td>\n",
       "      <td>neutral</td>\n",
       "      <td>RT @ Sm4bjp @ sardesairajdeep Some media walas...</td>\n",
       "      <td>['Eng', 'O', 'Eng', 'O', 'Hin', 'Hin', 'Eng', ...</td>\n",
       "      <td>rt mention sm4bjp mention sardesairajdeep some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9572</td>\n",
       "      <td>positive</td>\n",
       "      <td>@ aapkadharam Hello sir ji üôèüôèüôèüôèüôè Sir ji mere d...</td>\n",
       "      <td>['O', 'Hin', 'Hin', 'Hin', 'Hin', 'O', 'Hin', ...</td>\n",
       "      <td>mention aapkadharam hello sir ji sir ji mere d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24598</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@ OmarAyubKhan sir aaj subah sehri se light ka...</td>\n",
       "      <td>['O', 'Hin', 'Hin', 'Hin', 'Hin', 'Hin', 'Hin'...</td>\n",
       "      <td>mention omarayubkhan sir aaj subah sehri se li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id sentiment                                               text  \\\n",
       "0  23081   neutral  RT @ RD _ BANA Kahan Ho ???? Zinda Samadhi Kab...   \n",
       "1  29854  negative  In pro-indian hazraat ka Bughazzay Pak fauj da...   \n",
       "2  35319   neutral  RT @ Sm4bjp @ sardesairajdeep Some media walas...   \n",
       "3   9572  positive  @ aapkadharam Hello sir ji üôèüôèüôèüôèüôè Sir ji mere d...   \n",
       "4  24598   neutral  @ OmarAyubKhan sir aaj subah sehri se light ka...   \n",
       "\n",
       "                                     language_labels  \\\n",
       "0  ['Eng', 'O', 'Hin', 'O', 'Hin', 'Hin', 'Hin', ...   \n",
       "1  ['Eng', 'Eng', 'Hin', 'Hin', 'Eng', 'Hin', 'En...   \n",
       "2  ['Eng', 'O', 'Eng', 'O', 'Hin', 'Hin', 'Eng', ...   \n",
       "3  ['O', 'Hin', 'Hin', 'Hin', 'Hin', 'O', 'Hin', ...   \n",
       "4  ['O', 'Hin', 'Hin', 'Hin', 'Hin', 'Hin', 'Hin'...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  rt mention rd bana kahan ho zinda samadhi kab ...  \n",
       "1  in proindian hazraat ka bughazzay pak fauj dai...  \n",
       "2  rt mention sm4bjp mention sardesairajdeep some...  \n",
       "3  mention aapkadharam hello sir ji sir ji mere d...  \n",
       "4  mention omarayubkhan sir aaj subah sehri se li...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../data/processed_train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15131 entries, 0 to 15130\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               15131 non-null  int64 \n",
      " 1   sentiment        15131 non-null  object\n",
      " 2   text             15131 non-null  object\n",
      " 3   language_labels  15131 non-null  object\n",
      " 4   text_cleaned     15131 non-null  object\n",
      " 5   target           15131 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 709.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(df, classifier, vectorizer, random_search=False, param_grid=None, cv=5, n_iter_search=10):\n",
    "    \n",
    "    \n",
    "#     text_transformer = Pipeline(steps=[('vect', vectorizer)])\n",
    "#     preprocessor = ColumnTransformer(n_jobs=4, transformers=[('text', text_transformer, [\"text_cleaned\"])])\n",
    "\n",
    "    model = Pipeline(steps=[('vectorizer', vectorizer),\n",
    "                          ('classifier', classifier)])\n",
    "\n",
    "\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    df[\"target\"] = le.fit_transform(df['sentiment'])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['clean_text'].values, df[\"target\"].values.reshape(-1, 1), test_size=0.2, random_state=0)\n",
    "#     print(type(X_train), type(y_train), X_train.shape)\n",
    "   \n",
    "    if random_search and param_grid:\n",
    "        model = RandomizedSearchCV(model, param_grid, cv=cv, n_iter=n_iter_search, n_jobs=-1, refit=True)\n",
    "        \n",
    "        \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(\"model score: %.3f\" % model.score(X_test, y_test))\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "#     print(y_pred[0:10], y_pred.shape)\n",
    "    \n",
    "    scores = metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    return model, le, scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ridge_param_grid = {\n",
    "#                'preprocessor__text__tfidf__max_features': [75000, 100000, 50000],\n",
    "#                'regressor__alpha': stats.uniform()\n",
    "#               }\n",
    "# ridge, y_scaler1 = train_and_test_sklearn(df, Ridge(max_iter=200, tol=0.01), random_search=True, param_grid=ridge_param_grid, n_iter_search=10, cv=2)\n",
    "# testset_output1 = run_testset(testset, ridge, y_scaler1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Parameter value is not iterable or distribution (key='cv', value=3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-266e51d5afd3>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(df, classifier, vectorizer, random_search, param_grid, cv, n_iter_search)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model score: %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/sentimix/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/sentimix/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/sentimix/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1619\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1620\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/sentimix/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/sentimix/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, param_distributions, n_iter, random_state)\u001b[0m\n\u001b[1;32m    260\u001b[0m                     raise TypeError('Parameter value is not iterable '\n\u001b[1;32m    261\u001b[0m                                     \u001b[0;34m'or distribution (key={!r}, value={!r})'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                                     .format(key, dist[key]))\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Parameter value is not iterable or distribution (key='cv', value=3)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr_param_grid = {\n",
    "                'vectorizer__max_features': [50000, 100000],\n",
    "                'classifier__C': [0.1,1,5,10,100],\n",
    "                'classifier__penalty': ['l1', 'l2'],\n",
    "                    \n",
    "            }\n",
    "\n",
    "LR = LogisticRegression(C=4, max_iter=1000)\n",
    "tfidf = TfidfVectorizer(strip_accents=\"unicode\", max_features=100000, token_pattern='\\w+', ngram_range=(1, 2))\n",
    "\n",
    "# lr_pipeline, le, lr_scores = train_and_evaluate(data, LR, tfidf)\n",
    "lr_pipeline, le, lr_scores = train_and_evaluate(data, LR, tfidf, random_search=True, param_grid=lr_param_grid)\n",
    "lr_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vectorizer__max_features': 50000,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__C': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipeline.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_vectorizer__max_features</th>\n",
       "      <th>param_classifier__penalty</th>\n",
       "      <th>param_classifier__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.867930</td>\n",
       "      <td>0.084408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100000</td>\n",
       "      <td>l1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'vectorizer__max_features': 100000, 'classifi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.894753</td>\n",
       "      <td>3.630500</td>\n",
       "      <td>0.267992</td>\n",
       "      <td>0.024346</td>\n",
       "      <td>100000</td>\n",
       "      <td>l2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'vectorizer__max_features': 100000, 'classifi...</td>\n",
       "      <td>0.580870</td>\n",
       "      <td>0.596087</td>\n",
       "      <td>0.594783</td>\n",
       "      <td>0.611304</td>\n",
       "      <td>0.616355</td>\n",
       "      <td>0.599880</td>\n",
       "      <td>0.012678</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.952212</td>\n",
       "      <td>0.063167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50000</td>\n",
       "      <td>l1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'vectorizer__max_features': 50000, 'classifie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.081063</td>\n",
       "      <td>0.048666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50000</td>\n",
       "      <td>l1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'vectorizer__max_features': 50000, 'classifie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.890387</td>\n",
       "      <td>0.803464</td>\n",
       "      <td>0.230721</td>\n",
       "      <td>0.018165</td>\n",
       "      <td>50000</td>\n",
       "      <td>l2</td>\n",
       "      <td>1</td>\n",
       "      <td>{'vectorizer__max_features': 50000, 'classifie...</td>\n",
       "      <td>0.585217</td>\n",
       "      <td>0.588261</td>\n",
       "      <td>0.610870</td>\n",
       "      <td>0.622174</td>\n",
       "      <td>0.624619</td>\n",
       "      <td>0.606228</td>\n",
       "      <td>0.016603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.912451</td>\n",
       "      <td>0.049333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50000</td>\n",
       "      <td>l1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'vectorizer__max_features': 50000, 'classifie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.369458</td>\n",
       "      <td>0.657975</td>\n",
       "      <td>0.243769</td>\n",
       "      <td>0.035683</td>\n",
       "      <td>50000</td>\n",
       "      <td>l2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'vectorizer__max_features': 50000, 'classifie...</td>\n",
       "      <td>0.572609</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.582174</td>\n",
       "      <td>0.606957</td>\n",
       "      <td>0.600261</td>\n",
       "      <td>0.590487</td>\n",
       "      <td>0.012292</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.373211</td>\n",
       "      <td>0.055133</td>\n",
       "      <td>0.226372</td>\n",
       "      <td>0.025564</td>\n",
       "      <td>50000</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'vectorizer__max_features': 50000, 'classifie...</td>\n",
       "      <td>0.568261</td>\n",
       "      <td>0.566957</td>\n",
       "      <td>0.586522</td>\n",
       "      <td>0.605652</td>\n",
       "      <td>0.598521</td>\n",
       "      <td>0.585182</td>\n",
       "      <td>0.015603</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.003486</td>\n",
       "      <td>5.489806</td>\n",
       "      <td>0.213391</td>\n",
       "      <td>0.078421</td>\n",
       "      <td>100000</td>\n",
       "      <td>l2</td>\n",
       "      <td>10</td>\n",
       "      <td>{'vectorizer__max_features': 100000, 'classifi...</td>\n",
       "      <td>0.580435</td>\n",
       "      <td>0.596087</td>\n",
       "      <td>0.603478</td>\n",
       "      <td>0.618696</td>\n",
       "      <td>0.616355</td>\n",
       "      <td>0.603010</td>\n",
       "      <td>0.014014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.924534</td>\n",
       "      <td>0.093944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100000</td>\n",
       "      <td>l1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'vectorizer__max_features': 100000, 'classifi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.867930      0.084408         0.000000        0.000000   \n",
       "1      35.894753      3.630500         0.267992        0.024346   \n",
       "2       1.952212      0.063167         0.000000        0.000000   \n",
       "3       2.081063      0.048666         0.000000        0.000000   \n",
       "4       6.890387      0.803464         0.230721        0.018165   \n",
       "5       1.912451      0.049333         0.000000        0.000000   \n",
       "6      23.369458      0.657975         0.243769        0.035683   \n",
       "7       3.373211      0.055133         0.226372        0.025564   \n",
       "8      22.003486      5.489806         0.213391        0.078421   \n",
       "9       1.924534      0.093944         0.000000        0.000000   \n",
       "\n",
       "  param_vectorizer__max_features param_classifier__penalty  \\\n",
       "0                         100000                        l1   \n",
       "1                         100000                        l2   \n",
       "2                          50000                        l1   \n",
       "3                          50000                        l1   \n",
       "4                          50000                        l2   \n",
       "5                          50000                        l1   \n",
       "6                          50000                        l2   \n",
       "7                          50000                        l2   \n",
       "8                         100000                        l2   \n",
       "9                         100000                        l1   \n",
       "\n",
       "  param_classifier__C                                             params  \\\n",
       "0                   5  {'vectorizer__max_features': 100000, 'classifi...   \n",
       "1                 100  {'vectorizer__max_features': 100000, 'classifi...   \n",
       "2                   1  {'vectorizer__max_features': 50000, 'classifie...   \n",
       "3                 100  {'vectorizer__max_features': 50000, 'classifie...   \n",
       "4                   1  {'vectorizer__max_features': 50000, 'classifie...   \n",
       "5                   5  {'vectorizer__max_features': 50000, 'classifie...   \n",
       "6                 100  {'vectorizer__max_features': 50000, 'classifie...   \n",
       "7                 0.1  {'vectorizer__max_features': 50000, 'classifie...   \n",
       "8                  10  {'vectorizer__max_features': 100000, 'classifi...   \n",
       "9                  10  {'vectorizer__max_features': 100000, 'classifi...   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1           0.580870           0.596087           0.594783           0.611304   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "3                NaN                NaN                NaN                NaN   \n",
       "4           0.585217           0.588261           0.610870           0.622174   \n",
       "5                NaN                NaN                NaN                NaN   \n",
       "6           0.572609           0.590435           0.582174           0.606957   \n",
       "7           0.568261           0.566957           0.586522           0.605652   \n",
       "8           0.580435           0.596087           0.603478           0.618696   \n",
       "9                NaN                NaN                NaN                NaN   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0                NaN              NaN             NaN                6  \n",
       "1           0.616355         0.599880        0.012678                3  \n",
       "2                NaN              NaN             NaN                7  \n",
       "3                NaN              NaN             NaN                8  \n",
       "4           0.624619         0.606228        0.016603                1  \n",
       "5                NaN              NaN             NaN                9  \n",
       "6           0.600261         0.590487        0.012292                4  \n",
       "7           0.598521         0.585182        0.015603                5  \n",
       "8           0.616355         0.603010        0.014014                2  \n",
       "9                NaN              NaN             NaN               10  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lr_pipeline.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moinudeen/.pyenv/versions/3.7.2/envs/sentimix/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moinudeen/.pyenv/versions/3.7.2/envs/sentimix/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.613\n",
      "CPU times: user 1min 48s, sys: 2.16 s, total: 1min 50s\n",
      "Wall time: 15min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.5935483870967742,\n",
       "  'recall': 0.6789667896678967,\n",
       "  'f1-score': 0.6333907056798623,\n",
       "  'support': 813},\n",
       " '1': {'precision': 0.5548841893252769,\n",
       "  'recall': 0.507366482504604,\n",
       "  'f1-score': 0.53006253006253,\n",
       "  'support': 1086},\n",
       " '2': {'precision': 0.6922268907563025,\n",
       "  'recall': 0.6752049180327869,\n",
       "  'f1-score': 0.6836099585062242,\n",
       "  'support': 976},\n",
       " 'accuracy': 0.6128695652173913,\n",
       " 'macro avg': {'precision': 0.6135531557261179,\n",
       "  'recall': 0.6205127300684293,\n",
       "  'f1-score': 0.6156877314162056,\n",
       "  'support': 2875},\n",
       " 'weighted avg': {'precision': 0.6124426134591581,\n",
       "  'recall': 0.6128695652173913,\n",
       "  'f1-score': 0.611407955084421,\n",
       "  'support': 2875}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svc_param_grid = {\n",
    "                'vectorizer__max_features': [50000, 100000],\n",
    "                'classifier__gamma': ['scale', 'auto'], \n",
    "                'classifier__kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "                    \n",
    "            }\n",
    "\n",
    "\n",
    "svc = SVC()\n",
    "tfidf = TfidfVectorizer(strip_accents=\"unicode\", max_features=100000, token_pattern='\\w+', ngram_range=(1, 2))\n",
    "# svc_pipeline, le, svc_scores = train_and_evaluate(data, svc, tfidf)\n",
    "svc_pipeline, le, svc_scores = train_and_evaluate(data, svc, tfidf, random_search=True, param_grid=svc_param_grid)\n",
    "\n",
    "svc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vectorizer__max_features': 100000,\n",
       " 'classifier__kernel': 'sigmoid',\n",
       " 'classifier__gamma': 'scale'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_pipeline.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('vectorizer',\n",
       "                                              TfidfVectorizer(max_features=100000,\n",
       "                                                              ngram_range=(1,\n",
       "                                                                           2),\n",
       "                                                              strip_accents='unicode',\n",
       "                                                              token_pattern='\\\\w+')),\n",
       "                                             ('classifier', SVC())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'classifier__gamma': [1, 0.1, 'scale',\n",
       "                                                              'auto'],\n",
       "                                        'classifier__kernel': ['rbf', 'poly',\n",
       "                                                               'sigmoid'],\n",
       "                                        'vectorizer__max_features': [50000,\n",
       "                                                                     100000]})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(svc_pipeline.best_estimator_, '../models/svc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}